{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d987359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from netCDF4 import Dataset\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, box\n",
    "import pandas as pd\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "import rioxarray\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fde1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de671065",
   "metadata": {},
   "source": [
    "## Crop Planning Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6491878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Factor for N Requirement of Crops in China\n",
    "# S --> Planned Area of all crops [Major Only] --- Unit: 1000 hectares\n",
    "# S_Total --> Planned Area of all crops [Major + Minor] --- Unit: 1000 hectares\n",
    "# S_CropType --> Planned Area of each major croptype --- Unit: 1000 hectares\n",
    "# N_Total --> N Requirement of all major crops --- 10000 tons\n",
    "# R_CropType --> N Requirement of each major croptype --- Unit: Kg.N / ha\n",
    "\n",
    "S_Dict = {'2017': 154012, '2018': 153354, '2019': 152753}\n",
    "S_Total_Dict = {'2017':166332, '2018':165902, '2019':163931}\n",
    "\n",
    "S_crop_data_2017 = {\"Rice\": 30747, \"Wheat\": 24508, \"Corn\": 42399, \"Beans\": 10051, \"Tubers\": 7173,\\\n",
    "                  \"Oil-Bearing Crops\": 13223, \"Cotton\": 3195, \"Fiber Crops\": 58, \"Sugar Crops\": 1546,\\\n",
    "                  \"Tobacco\": 1131, \"Vegetables\": 19981,}\n",
    "S_crop_data_2018 = {\"Rice\": 30189, \"Wheat\": 24266, \"Corn\": 42130, \"Beans\": 10186, \"Tubers\": 7180,\\\n",
    "                  \"Oil-Bearing Crops\": 12872, \"Cotton\": 3354, \"Fiber Crops\": 57, \"Sugar Crops\": 1623, \\\n",
    "                  \"Tobacco\": 1058, \"Vegetables\": 20439}\n",
    "\n",
    "S_crop_data_2019 = {\"Rice\": 29694, \"Wheat\": 23728, \"Corn\": 41284, \"Beans\": 11075, \"Tubers\": 7142,\\\n",
    "                  \"Oil-Bearing Crops\": 12925, \"Cotton\": 3339, \"Fiber Crops\": 66, \"Sugar Crops\": 1610,\\\n",
    "                  \"Tobacco\": 1027, \"Vegetables\": 20863}\n",
    "S_CropType_Dict = {'2017': S_crop_data_2017, '2018': S_crop_data_2018, '2019': S_crop_data_2019,}\n",
    "\n",
    "N_Total_Dict = {'2017':2221.8, '2018':2065.4, '2019':1930.2}\n",
    "\n",
    "# Below is the Variable Info From the Zhang and Zhang (2012): UNIT is [kg/hectare]\n",
    "R_CropType_Dict = {\"Rice\": 200, \"Wheat\": 219,\"Corn\": 203, 'Beans': 55, \"Tubers\": 226, \\\n",
    "                   'Oil-Bearing Crops': 128, \"Cotton\": 341, \"Sugar Crops\": 360, \\\n",
    "                   \"Tobacco\": 140, \"Vegetables\": 335}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467bb8f4",
   "metadata": {},
   "source": [
    "## Decide types of crops planned in each grid of GFSAD1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2efd79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open GFSAD Data with China.shape\n",
    "\n",
    "def mask_gfsad_with_shapefile(gfsad_path, shapefile_path):\n",
    "    # Load the GFSAD data\n",
    "    gfsad_data = rioxarray.open_rasterio(gfsad_path)\n",
    "\n",
    "    # Load the shapefile\n",
    "    china_shape = gpd.read_file(shapefile_path)\n",
    "\n",
    "    # Set the CRS for the shapefile to EPSG:4326 if it is not set\n",
    "    if china_shape.crs is None:\n",
    "        china_shape.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    # Transform the shapefile CRS to match the GFSAD data CRS if they are different\n",
    "    if gfsad_data.rio.crs != china_shape.crs:\n",
    "        china_shape = china_shape.to_crs(gfsad_data.rio.crs)\n",
    "\n",
    "    # Clip the GFSAD data using the shapefile\n",
    "    gfsad_clipped = gfsad_data.rio.clip(china_shape.geometry.apply(mapping), china_shape.crs, drop=True)\n",
    "\n",
    "    return gfsad_clipped\n",
    "\n",
    "gfsad_path = '/global/scratch/users/liuwenjin021011/data/GFSAD1000/GFSAD1KCD.2010.001.2016348142525.tif'\n",
    "shapefile_path = '/global/home/users/liuwenjin021011/logs/fall_2023/China-Doundary-Shape.shp'\n",
    "\n",
    "# GFSAD_df = mask_gfsad_with_shapefile(gfsad_path, shapefile_path)[0] # this is only 1 band\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "869881b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide types of crop planned in each grid based on layer number: https://lpdaac.usgs.gov/products/gfsad1kcdv001\n",
    "\n",
    "GFSAD_Crop_Dict = {1: ['Wheat', 'Rice'], \n",
    "                   2: ['Wheat', 'Rice', 'Barley', 'Soybeans'], \\\n",
    "                   3: ['Wheat', 'Rice', 'Cotton', 'Orchards'],\\\n",
    "                   4: ['Wheat', 'Rice', 'Soybeans', 'Surgarcane', 'Corn', 'Cassava'],\\\n",
    "                   5: ['Wheat', 'Barley'],\\\n",
    "                   6: ['Corn', 'Soybeans'],\\\n",
    "                   7: ['Wheat', 'Corn', 'Rice', 'Barley', 'Soybeans'],\\\n",
    "                   8: ['Wheat', 'Maize', 'Rice', 'Barley', 'Soybeans']\n",
    "                  }\n",
    "\n",
    "# GFSAD_df[i][j] == layer_num is True, then GFSAD_df[i][j] has the corresponding planned crops\n",
    "def map_gfsad_to_crops(gfsad_df, crop_dict):\n",
    "    # Initialize an empty DataFrame to store the results\n",
    "    df = pd.DataFrame(columns=['x', 'y', 'planned_crops'])\n",
    "\n",
    "    # Iterate through each key-value pair in the GFSAD_Crop_Dict\n",
    "    for value, crops in crop_dict.items():\n",
    "        # Find the mask where GFSAD_df equals the current value\n",
    "        mask = gfsad_df == value\n",
    "\n",
    "        # Convert the mask to DataFrame\n",
    "        masked_df = mask.to_dataframe(name='mask')\n",
    "\n",
    "        # Filter out where mask is True\n",
    "        filtered_df = masked_df[masked_df['mask']]\n",
    "\n",
    "        # Create a column for planned crops\n",
    "        filtered_df['planned_crops'] = [crops for _ in range(len(filtered_df))]\n",
    "\n",
    "        # Append the result to the main DataFrame\n",
    "        df = pd.concat([df, filtered_df.reset_index()[['x', 'y', 'planned_crops']]], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# GFSAD_df = map_gfsad_to_crops(GFSAD_df, GFSAD_Crop_Dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8239fd2a",
   "metadata": {},
   "source": [
    "## Regrid GFSAD Grid to Match that of CHIRPS_SMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3854f13d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Over Sample GFSAD_df to Match the grid of CHIRPS_SMAP, and perserve the content of 'planned crops'\n",
    "# E.g.: if GFSAD_df[i][j] = ['A'], GFSAD_df[i+1][j] = ['B'], GFSAD_df[i][j+ 1] = ['C'], GFSAD_df[i+1][j+1] = ['A'],\n",
    "# and after regriding, [i][j], [i+1][j], [i][j+1], [i+1][j+1] match to a new grid, \n",
    "# then the 'planned_crops' for the new grid should be ['A', 'B', 'C']\n",
    "\n",
    "def get_grid_resolution(df, lat_col='lat', lon_col='lon'):\n",
    "    # Calculate differences in latitudes and longitudes\n",
    "    lat_diff = np.diff(sorted(df[lat_col].unique()))\n",
    "    lon_diff = np.diff(sorted(df[lon_col].unique()))\n",
    "\n",
    "    # Average resolution\n",
    "    lat_res = np.mean(lat_diff)\n",
    "    lon_res = np.mean(lon_diff)\n",
    "\n",
    "    return lat_res, lon_res\n",
    "\n",
    "# chirps_smap_res = get_grid_resolution(CHIRPS_SMAP_df)\n",
    "\n",
    "# GFSAD_df.rename(columns={'y': 'lat', 'x': 'lon'}, inplace=True)\n",
    "# gfsad_res = get_grid_resolution(GFSAD_df)\n",
    "\n",
    "# print(\"CHIRPS_SMAP Resolution:\", chirps_smap_res)\n",
    "# print(\"GFSAD Resolution:\", gfsad_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69537c59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def regrid_gfsad_to_match_chirps_smap(GFSAD_gdf, CHIRPS_SMAP_df):\n",
    "    # Define the grid size for CHIRPS_SMAP\n",
    "    delta_lon, delta_lat = 0.08829211718930399, 0.09336100444534785\n",
    "\n",
    "    # Convert CHIRPS_SMAP_df to GeoDataFrame with progress tracking\n",
    "    geometries = [box(lon - delta_lon/2, lat - delta_lat/2, lon + delta_lon/2, lat + delta_lat/2) \n",
    "                  for lon, lat in zip(CHIRPS_SMAP_df['lon'], CHIRPS_SMAP_df['lat'])]\n",
    "    CHIRPS_SMAP_gdf = gpd.GeoDataFrame(CHIRPS_SMAP_df, geometry=geometries, crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Perform spatial join with progress tracking\n",
    "    tqdm.tqdm.pandas(desc=\"Spatial Join Progress\")\n",
    "    joined_gdf = gpd.sjoin(CHIRPS_SMAP_gdf, GFSAD_gdf, how='left', op='intersects')\n",
    "\n",
    "    # Ensure all elements in 'planned_crops' are iterables (replace NaNs with empty lists)\n",
    "    joined_gdf['planned_crops'] = joined_gdf['planned_crops'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "    # Group by CHIRPS_SMAP grid and aggregate 'planned_crops'\n",
    "    tqdm.tqdm.pandas(desc=\"Aggregating Progress\")\n",
    "    regridded_gdf = joined_gdf.groupby(['lon_left', 'lat_left']).progress_apply(lambda x: list(set.union(*map(set, x['planned_crops'])))).reset_index()\n",
    "\n",
    "    # Rename columns\n",
    "    regridded_gdf.rename(columns={'lon_left': 'lon', 'lat_left': 'lat'}, inplace=True)\n",
    "\n",
    "    return regridded_gdf\n",
    "\n",
    "def regrid_in_chunks(GFSAD_gdf, CHIRPS_SMAP_df, chunk_size):\n",
    "    \n",
    "    # Initialize an empty DataFrame for the regridded data\n",
    "    regridded_df = pd.DataFrame(columns=['lon', 'lat', 'planned_crops'])\n",
    "\n",
    "    # Split the CHIRPS_SMAP_df into chunks\n",
    "    num_chunks = len(CHIRPS_SMAP_df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        print(f\"Processing chunk {i+1}/{num_chunks}...\")\n",
    "        sub_df = CHIRPS_SMAP_df.iloc[i * chunk_size: (i+1) * chunk_size]\n",
    "\n",
    "        # Perform spatial join and aggregation for each chunk\n",
    "        chunk_regridded = regrid_gfsad_to_match_chirps_smap(GFSAD_gdf, sub_df)\n",
    "        chunk_regridded.to_csv(f'/global/scratch/users/liuwenjin021011/data/GFSAD1000/Regridded_GFSAD_Chunk{i}_Year_2017_With_Status.csv', index = False, header = True)\n",
    "        # Append the results to the main DataFrame\n",
    "        regridded_df = pd.concat([regridded_df, chunk_regridded])\n",
    "        \n",
    "    \n",
    "    return regridded_df\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d899b137",
   "metadata": {},
   "source": [
    "# Convert GFSAD_df to GeoDataFrame with progress tracking\n",
    "points = []\n",
    "for lon, lat in tqdm.tqdm(zip(GFSAD_df['lon'], GFSAD_df['lat']), total=len(GFSAD_df), desc=\"Converting GFSAD_df\"):\n",
    "    points.append(Point(lon, lat))\n",
    "GFSAD_gdf = gpd.GeoDataFrame(GFSAD_df, geometry=points, crs=\"EPSG:4326\")\n",
    "\n",
    "# Define a suitable chunk size based on your system's memory capacity\n",
    "chunk_size =  1000000  \n",
    "\n",
    "# We do not need to calculate F for dry scheme, so lets keep Wet part for data processing\n",
    "Wet_CHIRPS_SMAP_df = CHIRPS_SMAP_df[CHIRPS_SMAP_df['status'] == 'wet']\n",
    "\n",
    "# Apply the function\n",
    "regridded_GFSAD_df = regrid_in_chunks(GFSAD_gdf, Wet_CHIRPS_SMAP_df, chunk_size)\n",
    "\n",
    "regridded_GFSAD_df.to_csv('/global/scratch/users/liuwenjin021011/data/GFSAD1000/Regridded_GFSAD_Year_2017_With_Status.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912410d",
   "metadata": {},
   "source": [
    "## Join Re-Gridded GFSAD data to CHIRPS-SMAP data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c4ed1a7",
   "metadata": {},
   "source": [
    "regridded_GFSAD_df = pd.read_csv('/global/scratch/users/liuwenjin021011/data/GFSAD1000/Regridded_GFSAD_Year_2019_With_Status.csv')\n",
    "regridded_GFSAD_df = regridded_GFSAD_df.drop(columns = ['planned_crops']).rename(columns = {'0':'planned crops'})\n",
    "regridded_GFSAD_df.head(2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e567836e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "CHIRPS_SMAP_df = pd.read_csv('/global/scratch/users/liuwenjin021011/data/FactorA_CHIRPS_SMAP_Year_2019_With_Status.csv')\n",
    "CHIRPS_SMAP_df = CHIRPS_SMAP_df[['lat', 'lon', 'interpolated_precip', 'temp', 'time','status']]\n",
    "CHIRPS_SMAP_df.head(2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a4eb9f5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "merged_df = pd.merge(CHIRPS_SMAP_df, regridded_GFSAD_df, on=['lat', 'lon'], how='left')\n",
    "merged_df = merged_df[['lat','lon','interpolated_precip','temp','time','status', 'planned crops']]\n",
    "\n",
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dba220ae",
   "metadata": {},
   "source": [
    "set(merged_df['planned crops'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d07b4f20",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# COnfirm that merged_df merged correctly\n",
    "\n",
    "GFSAD_df = GFSAD_df.rename(columns = {'y':'lat', 'x':'lon'})\n",
    "GFSAD_df[(GFSAD_df['lat'] > 47.01874549777733) & (GFSAD_df['lat'] < 47.11210650222267) \\\n",
    "         & (GFSAD_df['lon'] > 133.60212494140535) & (GFSAD_df['lon'] < 133.69041705859468)]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7df85d5d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(merged_df['planned crops'][0])\n",
    "merged_df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0790809",
   "metadata": {},
   "source": [
    "merged_df.to_csv('/global/scratch/users/liuwenjin021011/data/FactorA_CHIRPS_SMAP_GFSAD_Year_2019_With_Status.csv', index= False, header = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054cf06c",
   "metadata": {},
   "source": [
    "## Find SAI Value each grid \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1e1791c",
   "metadata": {},
   "source": [
    "# the proportion of each crop in each grid is calculated based on the total planned area in statistical yearbook\n",
    "# the corrected monthly N requirement is calculated by multiplying the planned proportion \n",
    "# with the N requirement of that crop, then summing all crops\n",
    "import json\n",
    "\n",
    "CHIRPS_SMAP_GFSAD_df = pd.read_csv('/global/scratch/users/liuwenjin021011/data/FactorA_CHIRPS_SMAP_GFSAD_Year_2017_With_Status_Upper_lat_Upper_lon.csv')\n",
    "\n",
    "# Convert JSON strings back to lists\n",
    "CHIRPS_SMAP_GFSAD_df['planned crops'] = CHIRPS_SMAP_GFSAD_df['planned crops'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22df623e",
   "metadata": {},
   "source": [
    "CHIRPS_SMAP_GFSAD_df = pd.read_csv('/global/scratch/users/liuwenjin021011/data/FactorA_CHIRPS_SMAP_GFSAD_Year_2017_With_Status.csv')\n",
    "\n",
    "CHIRPS_df = CHIRPS_SMAP_GFSAD_df\n",
    "lats = set(CHIRPS_df['lat'])\n",
    "lons = set(CHIRPS_df['lon'])\n",
    "\n",
    "lats = list(lats)\n",
    "lats.sort()\n",
    "lower_lats = lats[0:int(len(lats)/2)]\n",
    "upper_lats = lats[int(len(lats)/2):]\n",
    "\n",
    "lons = list(lons)\n",
    "lons.sort()\n",
    "lower_lons = lons[0:int(len(lons)/2)]\n",
    "upper_lons = lons[int(len(lons)/2):]\n",
    "\n",
    "lats = lower_lats\n",
    "lons = lower_lons\n",
    "\n",
    "CHIRPS_SMAP_GFSAD_df = CHIRPS_df[(CHIRPS_df['lat'] <= lats[-1]) & ((CHIRPS_df['lon'] <= lons[-1]))]\n",
    "\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming CHIRPS_SMAP_GFSAD_df is your DataFrame\n",
    "# Replace nan values with an empty list and convert string representations to actual lists\n",
    "# Using tqdm to track the progress\n",
    "tqdm.pandas(desc=\"Processing 'planned crops'\")\n",
    "CHIRPS_SMAP_GFSAD_df['planned crops'] = CHIRPS_SMAP_GFSAD_df['planned crops'].progress_apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Assuming df is your DataFrame and 'planned_crops' is the column with lists\n",
    "CHIRPS_SMAP_GFSAD_df['planned crops'] = CHIRPS_SMAP_GFSAD_df['planned crops'].apply(json.dumps)\n",
    "\n",
    "CHIRPS_SMAP_GFSAD_df.to_csv('/global/scratch/users/liuwenjin021011/data/FactorA_CHIRPS_SMAP_GFSAD_Year_2017_With_Status_Lower_lat_Lower_lon.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2f8fadf",
   "metadata": {},
   "source": [
    "GFSAD_crops = np.unique(CHIRPS_SMAP_GFSAD_df['planned crops'])\n",
    "\n",
    "GFSAD_unique_crops = []\n",
    "for crop_list in GFSAD_crops:\n",
    "    for crop in crop_list:\n",
    "        GFSAD_unique_crops += [crop]\n",
    "\n",
    "np.unique(GFSAD_unique_crops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18fbc2f",
   "metadata": {},
   "source": [
    "### Dictionary Keys Mapping\n",
    "#### Make Sure Planning Area, SAI Table, GFSAD Data have same set of keys/CropTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5afc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "GFSAD_crops = ['Barley', 'Cassava', 'Corn', 'Cotton', 'Maize', 'Orchards', 'Rice', 'Soybeans', 'Surgarcane', 'Wheat']\n",
    "\n",
    "SAI_Dict = {}\n",
    "SAI_Dict['Rice'] = 22.48 / 100\n",
    "SAI_Dict['Wheat'] = 0.47 / 100\n",
    "SAI_Dict['Corn'] = 32.3 / 100\n",
    "SAI_Dict['Soybean'] = 1.56 / 100\n",
    "SAI_Dict['Cotton'] = 2.29 / 100\n",
    "SAI_Dict['Rapeseed'] = 0.4 / 100\n",
    "SAI_Dict['Peanut'] = 0.12 / 100\n",
    "SAI_Dict['Cassava'] = 1.69 / 100\n",
    "SAI_Dict['Sugarcane'] = 18.72 / 100\n",
    "SAI_crops = list(SAI_Dict.keys())\n",
    "\n",
    "S_crops = list(S_CropType_Dict['2019'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9844305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S_CropType --> Planned Area of each major croptype --- Unit: 1000 hectares\n",
    "# Modify SAI Dict to Match the keys of S_CropType\n",
    "\n",
    "def map_SAI_to_S_crop_types(SAI_Dict, S_CropType_Dict):\n",
    "\n",
    "    crop_mapping = {\n",
    "        'Rice': 'Rice',\n",
    "        'Wheat': 'Wheat',\n",
    "        'Corn': 'Corn',\n",
    "        'Soybean': 'Beans',  \n",
    "        'Cassava' : 'Tubers',\n",
    "        'Peanut' : 'Oil-Bearing Crops',\n",
    "        'Rapeseed' : 'Oil-Bearing Crops',\n",
    "        'Cotton': 'Cotton',\n",
    "        'Sugarcane': 'Sugar Crops'\n",
    "       \n",
    "    }\n",
    "\n",
    "    # Initialize new dictionary with new keys and zero values\n",
    "    new_dict = {key: 0 for key in S_CropType_Dict}\n",
    "\n",
    "    # Iterate and sum the SAI for each new crop key\n",
    "    for old_key, value in SAI_Dict.items():\n",
    "        new_key = crop_mapping.get(old_key)\n",
    "        if new_key and new_key in new_dict:\n",
    "        \n",
    "            new_dict[new_key] += value\n",
    "\n",
    "    return new_dict\n",
    "\n",
    "# Notice that S_CropType_Dict keys are same for year 2017, 2018, 2019\n",
    "# Mapped_SAI_Dict = map_SAI_to_S_crop_types(SAI_Dict, S_CropType_Dict['2017'])\n",
    "# Mapped_SAI_Dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d0527",
   "metadata": {},
   "source": [
    "#### Crop Planning Month\n",
    "#### the SAI for each crop will not be calculated if crop is not planned in that month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70365292",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_growing_seasons = {\n",
    "    'Rice': [4, 5, 6, 7, 8, 9, 10],\n",
    "    'Wheat': [10, 11, 12, 1, 2, 3, 4, 5],\n",
    "    'Corn': [4, 5, 6, 7, 8, 9, 10],\n",
    "    'Beans': [4, 5, 6, 7, 8, 9],\n",
    "    'Tubers': [4, 5, 6, 7, 8, 9, 10],\n",
    "    'Oil-Bearing Crops': [4, 5, 6, 7, 8, 9],\n",
    "    'Cotton': [4, 5, 6, 7, 8, 9, 10],\n",
    "    'Fiber Crops': [4, 5, 6, 7, 8],\n",
    "    'Sugar Crops': [3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "    'Tobacco': [4, 5, 6, 7, 8, 9],\n",
    "    'Vegetables': [3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af8dbf2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_SAI(df, mapped_area_dict, n_requirement_dict, crop_mapping):\n",
    "    \n",
    "    # Calculate SAI\n",
    "    SAIs = []\n",
    "        \n",
    "    # Iterate through each row in the dataframe with tqdm progress bar\n",
    "    for index in tqdm(df.index, desc=\"Calculating SAI\", unit=\"row\"):\n",
    "        row = df.loc[index]\n",
    "        all_crops = row['planned crops']\n",
    "        if len(all_crops) == 0:\n",
    "            SAIs.append(0)\n",
    "            continue\n",
    "        # print('all crops:', all_crops)\n",
    "\n",
    "        # Find Unique Crops to avoid doubt counting\n",
    "        unique_crops = []\n",
    "        for crop in all_crops:\n",
    "            mapped_crop = crop_mapping.get(crop, crop)\n",
    "            if mapped_crop not in unique_crops:\n",
    "                unique_crops += [mapped_crop]       \n",
    "        # print('unique crops after mapping:', unique_crops)\n",
    "        \n",
    "        # Do not include the Crop is the Crop is not planned in the corresponding Month\n",
    "        unique_planned_crops = []\n",
    "        month = datetime.strptime(row['time'], \"%Y-%m-%d\").month\n",
    "        for crop in unique_crops:\n",
    "            mapped_crop = crop_mapping.get(crop, crop)\n",
    "            # print(month, crop, mapped_crop)\n",
    "            if crop_growing_seasons.get(mapped_crop):\n",
    "                if month in crop_growing_seasons.get(mapped_crop):\n",
    "                    unique_planned_crops += [mapped_crop]\n",
    "            \n",
    "        # print('unique crops growing in the month', month, ' are ', unique_planned_crops)\n",
    "        \n",
    "        # Calculate total planned area for all crops in this grid\n",
    "        planned_area = {}\n",
    "        for mapped_crop in unique_planned_crops:\n",
    "            planned_area[mapped_crop] = mapped_area_dict.get(mapped_crop, 0)\n",
    "        total_area = sum(planned_area.values())\n",
    "        # print(planned_area, total_area)\n",
    "        \n",
    "\n",
    "        total_pro = 0\n",
    "        if total_area > 0:\n",
    "            SAI = 0\n",
    "            for mapped_crop in unique_planned_crops:\n",
    "                crop_area = mapped_area_dict.get(mapped_crop, 0)\n",
    "                crop_proportion = crop_area / total_area\n",
    "                total_pro += crop_proportion\n",
    "\n",
    "                crop_SAI = Mapped_SAI_Dict.get(mapped_crop, 0)\n",
    "                # print(crop_SAI, crop_proportion, crop_SAI * crop_proportion, SAI)\n",
    "                SAI += crop_SAI * crop_proportion\n",
    "            \n",
    "            SAIs.append(SAI)\n",
    "            assert round(total_pro) == 1\n",
    "        else:\n",
    "            SAIs.append(0)\n",
    "\n",
    "    # print(SAIs)\n",
    "    df['SAI'] = SAIs\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# mapped_area_dict = S_CropType_Dict['2017']\n",
    "# test_df = calculate_SAI(CHIRPS_SMAP_GFSAD_df[27184:27185], mapped_area_dict, Mapped_SAI_Dict, crop_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7eb045",
   "metadata": {},
   "source": [
    "#### Convert Monthly N Requirement for each grid to Daily"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdad6f92",
   "metadata": {},
   "source": [
    "\n",
    "# Convert 'time' column to datetime\n",
    "CHIRPS_SMAP_GFSAD_df['time'] = pd.to_datetime(CHIRPS_SMAP_GFSAD_df['time'])\n",
    "\n",
    "\n",
    "# Initialize the 'N Requirement' column\n",
    "CHIRPS_SMAP_GFSAD_df['N Requirement'] = None\n",
    "\n",
    "# A dictionary to map month numbers to your column names\n",
    "month_to_column = {\n",
    "    1: 'N_Jan', 2: 'N_Feb', 3: 'N_Mar', 4: 'N_Apr', 5: 'N_May', 6: 'N_Jun',\n",
    "    7: 'N_Jul', 8: 'N_Aug', 9: 'N_Sep', 10: 'N_Oct', 11: 'N_Nov', 12: 'N_Dec'\n",
    "}\n",
    "\n",
    "# Assign the N requirement based on the month\n",
    "for index, row in CHIRPS_SMAP_GFSAD_df.iterrows():\n",
    "    month = row['time'].month\n",
    "    N_column = month_to_column[month]\n",
    "    \n",
    "    CHIRPS_SMAP_GFSAD_df.at[index, 'N Requirement'] = row[N_column]\n",
    "\n",
    "CHIRPS_SMAP_GFSAD_df = CHIRPS_SMAP_GFSAD_df.drop(columns = ['N_Jan','N_Feb','N_Mar','N_Apr','N_May','N_Jun',\\\n",
    "                                    'N_Jul','N_Aug','N_Sep','N_Oct','N_Nov','N_Dec'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "febb2f40",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Assuming df is your DataFrame and 'planned_crops' is the column with lists\n",
    "CHIRPS_SMAP_GFSAD_df['planned crops'] = CHIRPS_SMAP_GFSAD_df['planned crops'].apply(json.dumps)\n",
    "\n",
    "CHIRPS_SMAP_GFSAD_df.to_csv('/global/scratch/users/liuwenjin021011/data/FactorA_CHIRPS_SMAP_GFSAD_Year_2017_With_Status_With_F_Lower_lat_Lower_lon.csv', index = False, header = True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07b65186",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "mapped_area_dict = S_CropType_Dict['2017']\n",
    "# test_df = calculate_SAI(CHIRPS_SMAP_GFSAD_df[111000:111001], mapped_area_dict, Mapped_SAI_Dict, crop_mapping)\n",
    "\n",
    "chunk_size = 10000000\n",
    "start_chunk_index = 0\n",
    "total_rows = CHIRPS_SMAP_GFSAD_df.shape[0]\n",
    "chunk_num = (total_rows + chunk_size - 1) // chunk_size\n",
    "for chunk_index in np.arange(start_chunk_index, chunk_num):\n",
    "    \n",
    "    # Calculate Corrected N Requirement Each Grid Each Month\n",
    "    chunk_df = CHIRPS_SMAP_GFSAD_df[chunk_index * chunk_size: chunk_index * chunk_size + chunk_size]\n",
    "    chunk_df = calculate_SAI(chunk_df, mapped_area_dict, Mapped_SAI_Dict, crop_mapping)\n",
    "    \n",
    "    # Since we process Calculate SAI on rows, its alreay in Daily basis!\n",
    "    chunk_df['planned crops'] = chunk_df['planned crops'].apply(json.dumps)\n",
    "    chunk_df.to_csv(f'/global/scratch/users/liuwenjin021011/data/ThesisFactorC/SAI_Year2017_Upper_lats_Upper_lons_Chunk{chunk_index}.csv', index = False, header = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5a41a14",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "test_df = CHIRPS_SMAP_GFSAD_df\n",
    "test_df = test_df[(test_df['lat'] == test_df['lat'][111000]) & (test_df['lon'] == test_df['lon'][111000])]\n",
    "test_df = calculate_SAI(test_df, mapped_area_dict, Mapped_SAI_Dict, crop_mapping)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming test_df is your DataFrame\n",
    "\n",
    "# Convert 'time' column to datetime if it's not already\n",
    "test_df['time'] = pd.to_datetime(test_df['time'])\n",
    "\n",
    "# Sorting DataFrame by 'time'\n",
    "test_df.sort_values('time', inplace=True)\n",
    "\n",
    "# Define a color for each month\n",
    "colors = {\n",
    "    1: 'b', 2: 'g', 3: 'r', 4: 'c', 5: 'm', 6: 'y',\n",
    "    7: 'k', 8: 'orange', 9: 'purple', 10: 'brown', 11: 'pink', 12: 'gray'\n",
    "}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for month in range(1, 13):\n",
    "    # Filter data for each month\n",
    "    monthly_data = test_df[test_df['time'].dt.month == month]\n",
    "    \n",
    "    plt.plot(monthly_data['time'], monthly_data['SAI'], color=colors[month], label=month)\n",
    "\n",
    "# Formatting the plot\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('SAI')\n",
    "plt.title('SAI over Time')\n",
    "plt.legend(title='Month', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))  # Formatting date\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())  # One tick per month\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3105d0",
   "metadata": {},
   "source": [
    "## SAI Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df93f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lower_lat_Lower_lon = []\n",
    "Lower_lat_Upper_lon = []\n",
    "Upper_lat_Lower_lon = []\n",
    "Upper_lat_Upper_lon = []\n",
    "F_dir = '/global/scratch/users/liuwenjin021011/data/ThesisFactorC/'\n",
    "for file in os.listdir(F_dir):\n",
    "    if 'Year2019_Lower_lats_Lower_lons' in file:\n",
    "        Lower_lat_Lower_lon += [F_dir + file]\n",
    "        \n",
    "    if 'Year2019_Lower_lats_Upper_lons' in file:\n",
    "        Lower_lat_Upper_lon += [F_dir + file]\n",
    "        \n",
    "    if 'Year2019_Upper_lats_Lower_lons' in file:\n",
    "        Upper_lat_Lower_lon += [F_dir + file]\n",
    "    \n",
    "    if 'Year2019_Upper_lats_Upper_lons' in file:\n",
    "        Upper_lat_Upper_lon += [F_dir + file]\n",
    "        \n",
    "Lower_lat_Lower_lon.sort()\n",
    "Lower_lat_Upper_lon.sort()\n",
    "Upper_lat_Lower_lon.sort()\n",
    "Upper_lat_Upper_lon.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c704124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7951b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_file(file_list, save_name):\n",
    "    all_df = pd.DataFrame()\n",
    "    for file in file_list:\n",
    "        chunk_df = pd.read_csv(file)\n",
    "        all_df = pd.concat([all_df, chunk_df])\n",
    "        # print(file)\n",
    "    # all_df = all_df.drop(columns = ['Unnamed: 0'])\n",
    "    all_df = all_df.drop_duplicates()\n",
    "    all_df.to_csv(f'/global/scratch/users/liuwenjin021011/data/ThesisFactorC/Year2019_{save_name}.csv')\n",
    "\n",
    "    \n",
    "merge_file(Lower_lat_Lower_lon, 'Lower_lat_Lower_lon')\n",
    "merge_file(Lower_lat_Upper_lon, 'Lower_lat_Upper_lon')\n",
    "merge_file(Upper_lat_Lower_lon, 'Upper_lat_Lower_lon')\n",
    "merge_file(Upper_lat_Upper_lon, 'Upper_lat_Upper_lon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcfbb14",
   "metadata": {},
   "source": [
    "## SAI Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "235466e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_df = pd.read_csv('/global/scratch/users/liuwenjin021011/data/ThesisFactorC/Year2019_Lower_lat_Lower_lon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "077a6d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_df = pd.read_csv('/global/scratch/users/liuwenjin021011/data/ThesisFactorC/Year2019_Lower_lat_Upper_lon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d35209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_df = pd.read_csv('/global/scratch/users/liuwenjin021011/data/ThesisFactorC/Year2019_Upper_lat_Lower_lon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2809fd27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uu_df = pd.read_csv('/global/scratch/users/liuwenjin021011/data/ThesisFactorC/Year2019_Upper_lat_Upper_lon.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a9c4ea2",
   "metadata": {},
   "source": [
    "ll_df = ll_df.drop(columns = ['Unnamed: 0'])\n",
    "ll_df = ll_df.drop_duplicates()\n",
    "ll_df.to_csv('/global/scratch/users/liuwenjin021011/data/ThesisFactorC/Year2017_Lower_lat_Lower_lon.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fa7534d",
   "metadata": {},
   "source": [
    "lu_df = lu_df.drop(columns = ['Unnamed: 0'])\n",
    "lu_df = lu_df.drop_duplicates()\n",
    "lu_df.to_csv('/global/scratch/users/liuwenjin021011/data/ThesisFactorC/Year2017_Lower_lat_Upper_lon.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50053568",
   "metadata": {},
   "source": [
    "ul_df = ul_df.drop(columns = ['Unnamed: 0'])\n",
    "ul_df = ul_df.drop_duplicates()\n",
    "ul_df.to_csv('/global/scratch/users/liuwenjin021011/data/ThesisFactorC/Year2017_Upper_lat_Lower_lon.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d0923ca",
   "metadata": {},
   "source": [
    "uu_df = uu_df.drop(columns = ['Unnamed: 0'])\n",
    "uu_df = uu_df.drop_duplicates()\n",
    "uu_df.to_csv('/global/scratch/users/liuwenjin021011/data/ThesisFactorC/Year2017_Upper_lat_Upper_lon.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fea4757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ll_df, lu_df, ul_df, uu_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3e2087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/global/scratch/users/liuwenjin021011/data/ThesisFactorC/Year2019_SAI.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c583d341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NOx_selina",
   "language": "python",
   "name": "nox_selina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
